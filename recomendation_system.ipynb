{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4040faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "748c7aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>Alan</td>\n",
       "      <td>Reynolds</td>\n",
       "      <td>alan.reynolds.1996@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>Construction Engineer</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>thomas.gilbert.1997@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Cross</td>\n",
       "      <td>madison.cross.1998@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>97</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Brittany</td>\n",
       "      <td>Compton</td>\n",
       "      <td>brittany.compton.1999@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>51</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2000</td>\n",
       "      <td>Natalie</td>\n",
       "      <td>Smith</td>\n",
       "      <td>natalie.smith.2000@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>82</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id first_name last_name                                    email  \\\n",
       "0        1       Paul     Casey           paul.casey.1@gslingacademy.com   \n",
       "1        2   Danielle  Sandoval    danielle.sandoval.2@gslingacademy.com   \n",
       "2        3       Tina   Andrews         tina.andrews.3@gslingacademy.com   \n",
       "3        4       Tara     Clark           tara.clark.4@gslingacademy.com   \n",
       "4        5    Anthony    Campos       anthony.campos.5@gslingacademy.com   \n",
       "...    ...        ...       ...                                      ...   \n",
       "1995  1996       Alan  Reynolds     alan.reynolds.1996@gslingacademy.com   \n",
       "1996  1997     Thomas   Gilbert    thomas.gilbert.1997@gslingacademy.com   \n",
       "1997  1998    Madison     Cross     madison.cross.1998@gslingacademy.com   \n",
       "1998  1999   Brittany   Compton  brittany.compton.1999@gslingacademy.com   \n",
       "1999  2000    Natalie     Smith     natalie.smith.2000@gslingacademy.com   \n",
       "\n",
       "      gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0       male          False             3                       False   \n",
       "1     female          False             2                       False   \n",
       "2     female          False             9                        True   \n",
       "3     female          False             5                       False   \n",
       "4       male          False             5                       False   \n",
       "...      ...            ...           ...                         ...   \n",
       "1995    male          False             2                       False   \n",
       "1996    male          False             2                       False   \n",
       "1997  female          False             5                       False   \n",
       "1998  female           True            10                        True   \n",
       "1999  female          False             5                       False   \n",
       "\n",
       "      weekly_self_study_hours      career_aspiration  math_score  \\\n",
       "0                          27                 Lawyer          73   \n",
       "1                          47                 Doctor          90   \n",
       "2                          13     Government Officer          81   \n",
       "3                           3                 Artist          71   \n",
       "4                          10                Unknown          84   \n",
       "...                       ...                    ...         ...   \n",
       "1995                       30  Construction Engineer          83   \n",
       "1996                       20      Software Engineer          89   \n",
       "1997                       14      Software Engineer          97   \n",
       "1998                        5         Business Owner          51   \n",
       "1999                       27             Accountant          82   \n",
       "\n",
       "      history_score  physics_score  chemistry_score  biology_score  \\\n",
       "0                81             93               97             63   \n",
       "1                86             96              100             90   \n",
       "2                97             95               96             65   \n",
       "3                74             88               80             89   \n",
       "4                77             65               65             80   \n",
       "...             ...            ...              ...            ...   \n",
       "1995             77             84               73             75   \n",
       "1996             65             73               80             87   \n",
       "1997             85             63               93             68   \n",
       "1998             96             72               89             95   \n",
       "1999             99             91               69             83   \n",
       "\n",
       "      english_score  geography_score  \n",
       "0                80               87  \n",
       "1                88               90  \n",
       "2                77               94  \n",
       "3                63               86  \n",
       "4                74               76  \n",
       "...             ...              ...  \n",
       "1995             84               82  \n",
       "1996             67               73  \n",
       "1997             94               78  \n",
       "1998             88               75  \n",
       "1999             93              100  \n",
       "\n",
       "[2000 rows x 17 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"student-scores.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ae3eb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                            0\n",
       "first_name                    0\n",
       "last_name                     0\n",
       "email                         0\n",
       "gender                        0\n",
       "part_time_job                 0\n",
       "absence_days                  0\n",
       "extracurricular_activities    0\n",
       "weekly_self_study_hours       0\n",
       "career_aspiration             0\n",
       "math_score                    0\n",
       "history_score                 0\n",
       "physics_score                 0\n",
       "chemistry_score               0\n",
       "biology_score                 0\n",
       "english_score                 0\n",
       "geography_score               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "295e87ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>Construction Engineer</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>97</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>51</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>82</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      part_time_job  absence_days  extracurricular_activities  \\\n",
       "0             False             3                       False   \n",
       "1             False             2                       False   \n",
       "2             False             9                        True   \n",
       "3             False             5                       False   \n",
       "4             False             5                       False   \n",
       "...             ...           ...                         ...   \n",
       "1995          False             2                       False   \n",
       "1996          False             2                       False   \n",
       "1997          False             5                       False   \n",
       "1998           True            10                        True   \n",
       "1999          False             5                       False   \n",
       "\n",
       "      weekly_self_study_hours      career_aspiration  math_score  \\\n",
       "0                          27                 Lawyer          73   \n",
       "1                          47                 Doctor          90   \n",
       "2                          13     Government Officer          81   \n",
       "3                           3                 Artist          71   \n",
       "4                          10                Unknown          84   \n",
       "...                       ...                    ...         ...   \n",
       "1995                       30  Construction Engineer          83   \n",
       "1996                       20      Software Engineer          89   \n",
       "1997                       14      Software Engineer          97   \n",
       "1998                        5         Business Owner          51   \n",
       "1999                       27             Accountant          82   \n",
       "\n",
       "      history_score  physics_score  chemistry_score  biology_score  \\\n",
       "0                81             93               97             63   \n",
       "1                86             96              100             90   \n",
       "2                97             95               96             65   \n",
       "3                74             88               80             89   \n",
       "4                77             65               65             80   \n",
       "...             ...            ...              ...            ...   \n",
       "1995             77             84               73             75   \n",
       "1996             65             73               80             87   \n",
       "1997             85             63               93             68   \n",
       "1998             96             72               89             95   \n",
       "1999             99             91               69             83   \n",
       "\n",
       "      english_score  geography_score  \n",
       "0                80               87  \n",
       "1                88               90  \n",
       "2                77               94  \n",
       "3                63               86  \n",
       "4                74               76  \n",
       "...             ...              ...  \n",
       "1995             84               82  \n",
       "1996             67               73  \n",
       "1997             94               78  \n",
       "1998             88               75  \n",
       "1999             93              100  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[\"id\",\"first_name\",\"last_name\",\"email\",\"gender\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "aa577214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27],\n",
       "       [47],\n",
       "       [13],\n",
       "       ...,\n",
       "       [14],\n",
       "       [ 5],\n",
       "       [27]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.iloc[:,3:4].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "81be72d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absence_days</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absence_days  math_score  history_score  physics_score  chemistry_score  \\\n",
       "0                3          73             81             93               97   \n",
       "1                2          90             86             96              100   \n",
       "2                9          81             97             95               96   \n",
       "3                5          71             74             88               80   \n",
       "4                5          84             77             65               65   \n",
       "...            ...         ...            ...            ...              ...   \n",
       "1995             2          83             77             84               73   \n",
       "1996             2          89             65             73               80   \n",
       "1997             5          97             85             63               93   \n",
       "1998            10          51             96             72               89   \n",
       "1999             5          82             99             91               69   \n",
       "\n",
       "      biology_score  english_score  geography_score  \n",
       "0                63             80               87  \n",
       "1                90             88               90  \n",
       "2                65             77               94  \n",
       "3                89             63               86  \n",
       "4                80             74               76  \n",
       "...             ...            ...              ...  \n",
       "1995             75             84               82  \n",
       "1996             87             67               73  \n",
       "1997             68             94               78  \n",
       "1998             95             88               75  \n",
       "1999             83             93              100  \n",
       "\n",
       "[2000 rows x 8 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.get([\"absence_days\",\"math_score\",\"history_score\",\"physics_score\",\"chemistry_score\",\"biology_score\",\"english_score\",\"geography_score\"])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6f8b755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Lawyer'],\n",
       "       ['Doctor'],\n",
       "       ['Government Officer'],\n",
       "       ...,\n",
       "       ['Software Engineer'],\n",
       "       ['Business Owner'],\n",
       "       ['Accountant']], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "career = df.iloc[:,4:5].values\n",
    "career"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9b13a399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Área de Trabalho/curso_tensorflow/venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/tmp/ipykernel_686666/3896376793.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[\"career\"] = career_encoded\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absence_days</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>77</td>\n",
       "      <td>84</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>85</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>96</td>\n",
       "      <td>72</td>\n",
       "      <td>89</td>\n",
       "      <td>95</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "      <td>99</td>\n",
       "      <td>91</td>\n",
       "      <td>69</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      absence_days  math_score  history_score  physics_score  chemistry_score  \\\n",
       "0                3          73             81             93               97   \n",
       "1                2          90             86             96              100   \n",
       "2                9          81             97             95               96   \n",
       "3                5          71             74             88               80   \n",
       "4                5          84             77             65               65   \n",
       "...            ...         ...            ...            ...              ...   \n",
       "1995             2          83             77             84               73   \n",
       "1996             2          89             65             73               80   \n",
       "1997             5          97             85             63               93   \n",
       "1998            10          51             96             72               89   \n",
       "1999             5          82             99             91               69   \n",
       "\n",
       "      biology_score  english_score  geography_score  career  \n",
       "0                63             80               87       9  \n",
       "1                90             88               90       6  \n",
       "2                65             77               94       8  \n",
       "3                89             63               86       1  \n",
       "4                80             74               76      15  \n",
       "...             ...            ...              ...     ...  \n",
       "1995             75             84               82       4  \n",
       "1996             87             67               73      12  \n",
       "1997             68             94               78      12  \n",
       "1998             95             88               75       3  \n",
       "1999             83             93              100       0  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_career = LabelEncoder()\n",
    "scaler_career = StandardScaler()\n",
    "career_encoded = encoder_career.fit_transform(career)\n",
    "x[\"career\"] = career_encoded\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "573cdd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Área de Trabalho/curso_tensorflow/venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/lucas/Área de Trabalho/curso_tensorflow/venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 0]), array([0, 0, 0, ..., 0, 1, 0]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracurricular = df.iloc[:,2:3].values\n",
    "job = df.iloc[:,0:1].values\n",
    "\n",
    "encoder_extracurricular_job = LabelEncoder()\n",
    "extracurricular_encoded = encoder_extracurricular_job.fit_transform(extracurricular)\n",
    "job_encoded = encoder_extracurricular_job.transform(job)\n",
    "\n",
    "extracurricular_encoded,job_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "394c5a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.25317528, -0.79052462,  0.05246267, ...,  0.25621736,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.63360395,  0.49525021,  0.44514737, ..., -0.34429208,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.02939675, -0.18545411,  1.30905369, ...,  0.05604755,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.50768206,  1.02468691,  0.36661043, ...,  0.85672681,\n",
       "         0.        ,  0.        ],\n",
       "       [ 2.40982542, -2.45446852,  1.23051675, ..., -0.94480153,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.50768206, -0.1098203 ,  1.46612756, ..., -1.54531098,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler_x = StandardScaler()\n",
    "x_final = x.iloc[:,:].values\n",
    "\n",
    "x_final_scaler = scaler_x.fit_transform(x_final)\n",
    "# Append extracurricular_encoded and job_encoded as new columns\n",
    "x_final_scaler = np.column_stack((x_final_scaler, extracurricular_encoded, job_encoded))\n",
    "x_final_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "335f8cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2000.000000\n",
       "mean       17.755500\n",
       "std        12.129604\n",
       "min         0.000000\n",
       "25%         5.000000\n",
       "50%        18.000000\n",
       "75%        28.000000\n",
       "max        50.000000\n",
       "Name: weekly_self_study_hours, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"weekly_self_study_hours\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "646a5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_y = StandardScaler()\n",
    "y_final = scaler_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "103b9637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_final_scaler, y_final, test_size=0.3, random_state=42)\n",
    "x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)\n",
    "y_train = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33100c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1400, 11])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0391e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT_DIR = os.path.join(os.curdir,\"logs_recomendations\")\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(ROOT_DIR, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fc6cefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(run_logdir)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9e6ecf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2c75793f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/Área de Trabalho/curso_tensorflow/venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.0000e+00 - loss: 1.0498 - val_accuracy: 0.0000e+00 - val_loss: 1.1410\n",
      "Epoch 2/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 1.0023 - val_accuracy: 0.0000e+00 - val_loss: 1.1203\n",
      "Epoch 3/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.9644 - val_accuracy: 0.0000e+00 - val_loss: 1.0705\n",
      "Epoch 4/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.8211 - val_accuracy: 0.0000e+00 - val_loss: 0.8795\n",
      "Epoch 5/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.7028 - val_accuracy: 0.0000e+00 - val_loss: 0.8125\n",
      "Epoch 6/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6620 - val_accuracy: 0.0000e+00 - val_loss: 0.7092\n",
      "Epoch 7/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6253 - val_accuracy: 0.0000e+00 - val_loss: 0.7288\n",
      "Epoch 8/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6592 - val_accuracy: 0.0000e+00 - val_loss: 0.6818\n",
      "Epoch 9/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6215 - val_accuracy: 0.0000e+00 - val_loss: 0.7077\n",
      "Epoch 10/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5589 - val_accuracy: 0.0000e+00 - val_loss: 0.6337\n",
      "Epoch 11/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5649 - val_accuracy: 0.0000e+00 - val_loss: 0.6666\n",
      "Epoch 12/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.6177 - val_accuracy: 0.0000e+00 - val_loss: 0.6257\n",
      "Epoch 13/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5527 - val_accuracy: 0.0000e+00 - val_loss: 0.6183\n",
      "Epoch 14/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5823 - val_accuracy: 0.0000e+00 - val_loss: 0.6444\n",
      "Epoch 15/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5475 - val_accuracy: 0.0000e+00 - val_loss: 0.6070\n",
      "Epoch 16/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 0.6173\n",
      "Epoch 17/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5144 - val_accuracy: 0.0000e+00 - val_loss: 0.6526\n",
      "Epoch 18/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5231 - val_accuracy: 0.0000e+00 - val_loss: 0.6152\n",
      "Epoch 19/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4976 - val_accuracy: 0.0000e+00 - val_loss: 0.6333\n",
      "Epoch 20/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.5010 - val_accuracy: 0.0000e+00 - val_loss: 0.6435\n",
      "Epoch 21/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4742 - val_accuracy: 0.0000e+00 - val_loss: 0.6604\n",
      "Epoch 22/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4608 - val_accuracy: 0.0000e+00 - val_loss: 0.6232\n",
      "Epoch 23/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4835 - val_accuracy: 0.0000e+00 - val_loss: 0.6277\n",
      "Epoch 24/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4585 - val_accuracy: 0.0000e+00 - val_loss: 0.6436\n",
      "Epoch 25/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.4638 - val_accuracy: 0.0000e+00 - val_loss: 0.6923\n",
      "Epoch 26/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4445 - val_accuracy: 0.0000e+00 - val_loss: 0.6414\n",
      "Epoch 27/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4503 - val_accuracy: 0.0000e+00 - val_loss: 0.6884\n",
      "Epoch 28/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3990 - val_accuracy: 0.0000e+00 - val_loss: 0.6232\n",
      "Epoch 29/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4405 - val_accuracy: 0.0000e+00 - val_loss: 0.6917\n",
      "Epoch 30/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4564 - val_accuracy: 0.0000e+00 - val_loss: 0.6567\n",
      "Epoch 31/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3938 - val_accuracy: 0.0000e+00 - val_loss: 0.6581\n",
      "Epoch 32/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3966 - val_accuracy: 0.0000e+00 - val_loss: 0.7018\n",
      "Epoch 33/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4286 - val_accuracy: 0.0000e+00 - val_loss: 0.7090\n",
      "Epoch 34/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4157 - val_accuracy: 0.0000e+00 - val_loss: 0.7121\n",
      "Epoch 35/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.4125 - val_accuracy: 0.0000e+00 - val_loss: 0.7288\n",
      "Epoch 36/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3871 - val_accuracy: 0.0000e+00 - val_loss: 0.7040\n",
      "Epoch 37/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3920 - val_accuracy: 0.0000e+00 - val_loss: 0.7166\n",
      "Epoch 38/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3817 - val_accuracy: 0.0000e+00 - val_loss: 0.6686\n",
      "Epoch 39/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3745 - val_accuracy: 0.0000e+00 - val_loss: 0.6547\n",
      "Epoch 40/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3719 - val_accuracy: 0.0000e+00 - val_loss: 0.7307\n",
      "Epoch 41/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3650 - val_accuracy: 0.0000e+00 - val_loss: 0.6545\n",
      "Epoch 42/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3636 - val_accuracy: 0.0000e+00 - val_loss: 0.6838\n",
      "Epoch 43/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3689 - val_accuracy: 0.0000e+00 - val_loss: 0.6914\n",
      "Epoch 44/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3397 - val_accuracy: 0.0000e+00 - val_loss: 0.6784\n",
      "Epoch 45/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3481 - val_accuracy: 0.0000e+00 - val_loss: 0.6910\n",
      "Epoch 46/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2870 - val_accuracy: 0.0000e+00 - val_loss: 0.6774\n",
      "Epoch 47/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3241 - val_accuracy: 0.0000e+00 - val_loss: 0.6865\n",
      "Epoch 48/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3087 - val_accuracy: 0.0000e+00 - val_loss: 0.7010\n",
      "Epoch 49/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2919 - val_accuracy: 0.0000e+00 - val_loss: 0.7096\n",
      "Epoch 50/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3084 - val_accuracy: 0.0000e+00 - val_loss: 0.7187\n",
      "Epoch 51/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3143 - val_accuracy: 0.0000e+00 - val_loss: 0.7523\n",
      "Epoch 52/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3186 - val_accuracy: 0.0000e+00 - val_loss: 0.6768\n",
      "Epoch 53/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2926 - val_accuracy: 0.0000e+00 - val_loss: 0.7244\n",
      "Epoch 54/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3075 - val_accuracy: 0.0000e+00 - val_loss: 0.7581\n",
      "Epoch 55/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3119 - val_accuracy: 0.0000e+00 - val_loss: 0.7418\n",
      "Epoch 56/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3199 - val_accuracy: 0.0000e+00 - val_loss: 0.8154\n",
      "Epoch 57/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2886 - val_accuracy: 0.0000e+00 - val_loss: 0.7795\n",
      "Epoch 58/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.2888 - val_accuracy: 0.0000e+00 - val_loss: 0.8077\n",
      "Epoch 59/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.3124 - val_accuracy: 0.0000e+00 - val_loss: 0.7727\n",
      "Epoch 60/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3003 - val_accuracy: 0.0000e+00 - val_loss: 0.8734\n",
      "Epoch 61/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3120 - val_accuracy: 0.0000e+00 - val_loss: 0.7982\n",
      "Epoch 62/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2966 - val_accuracy: 0.0000e+00 - val_loss: 0.7835\n",
      "Epoch 63/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2566 - val_accuracy: 0.0000e+00 - val_loss: 0.7882\n",
      "Epoch 64/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2732 - val_accuracy: 0.0000e+00 - val_loss: 0.8221\n",
      "Epoch 65/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.3005 - val_accuracy: 0.0000e+00 - val_loss: 0.7446\n",
      "Epoch 66/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2887 - val_accuracy: 0.0000e+00 - val_loss: 0.7713\n",
      "Epoch 67/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2648 - val_accuracy: 0.0000e+00 - val_loss: 0.7556\n",
      "Epoch 68/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2701 - val_accuracy: 0.0000e+00 - val_loss: 0.7563\n",
      "Epoch 69/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 0.2795 - val_accuracy: 0.0000e+00 - val_loss: 0.8061\n",
      "Epoch 70/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2838 - val_accuracy: 0.0000e+00 - val_loss: 0.7419\n",
      "Epoch 71/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2812 - val_accuracy: 0.0000e+00 - val_loss: 0.7617\n",
      "Epoch 72/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2478 - val_accuracy: 0.0000e+00 - val_loss: 0.7739\n",
      "Epoch 73/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2565 - val_accuracy: 0.0000e+00 - val_loss: 0.7951\n",
      "Epoch 74/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2579 - val_accuracy: 0.0000e+00 - val_loss: 0.8012\n",
      "Epoch 75/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2463 - val_accuracy: 0.0000e+00 - val_loss: 0.8049\n",
      "Epoch 76/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2368 - val_accuracy: 0.0000e+00 - val_loss: 0.7982\n",
      "Epoch 77/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2380 - val_accuracy: 0.0000e+00 - val_loss: 0.8135\n",
      "Epoch 78/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2347 - val_accuracy: 0.0000e+00 - val_loss: 0.7866\n",
      "Epoch 79/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2128 - val_accuracy: 0.0000e+00 - val_loss: 0.7601\n",
      "Epoch 80/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2143 - val_accuracy: 0.0000e+00 - val_loss: 0.7868\n",
      "Epoch 81/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2125 - val_accuracy: 0.0000e+00 - val_loss: 0.7760\n",
      "Epoch 82/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2151 - val_accuracy: 0.0000e+00 - val_loss: 0.7848\n",
      "Epoch 83/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2119 - val_accuracy: 0.0000e+00 - val_loss: 0.8658\n",
      "Epoch 84/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2189 - val_accuracy: 0.0000e+00 - val_loss: 0.7687\n",
      "Epoch 85/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2289 - val_accuracy: 0.0000e+00 - val_loss: 0.8081\n",
      "Epoch 86/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1922 - val_accuracy: 0.0000e+00 - val_loss: 0.7909\n",
      "Epoch 87/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1954 - val_accuracy: 0.0000e+00 - val_loss: 0.7957\n",
      "Epoch 88/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2060 - val_accuracy: 0.0000e+00 - val_loss: 0.7915\n",
      "Epoch 89/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1973 - val_accuracy: 0.0000e+00 - val_loss: 0.8047\n",
      "Epoch 90/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1938 - val_accuracy: 0.0000e+00 - val_loss: 0.8163\n",
      "Epoch 91/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1831 - val_accuracy: 0.0000e+00 - val_loss: 0.8061\n",
      "Epoch 92/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1981 - val_accuracy: 0.0000e+00 - val_loss: 0.7659\n",
      "Epoch 93/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1996 - val_accuracy: 0.0000e+00 - val_loss: 0.7989\n",
      "Epoch 94/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2077 - val_accuracy: 0.0000e+00 - val_loss: 0.8187\n",
      "Epoch 95/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2028 - val_accuracy: 0.0000e+00 - val_loss: 0.7697\n",
      "Epoch 96/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2554 - val_accuracy: 0.0000e+00 - val_loss: 0.8347\n",
      "Epoch 97/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2405 - val_accuracy: 0.0000e+00 - val_loss: 0.8559\n",
      "Epoch 98/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1959 - val_accuracy: 0.0000e+00 - val_loss: 0.8230\n",
      "Epoch 99/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.1917 - val_accuracy: 0.0000e+00 - val_loss: 0.8456\n",
      "Epoch 100/100\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 0.2215 - val_accuracy: 0.0000e+00 - val_loss: 0.9062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f19206b9930>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(128,activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128,activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(64,activation=\"elu\",kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1,activation=\"tanh\"),\n",
    "])\n",
    "\n",
    "optmizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optmizer, metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=100,batch_size=64,validation_split=0.3,callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d27b4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[[26.798567 ]\n",
      " [13.84438  ]\n",
      " [ 6.5089397]\n",
      " [27.32452  ]\n",
      " [ 5.658456 ]\n",
      " [15.805664 ]\n",
      " [ 8.876887 ]\n",
      " [20.146748 ]\n",
      " [ 5.6397247]\n",
      " [29.878565 ]\n",
      " [ 9.605183 ]\n",
      " [11.688513 ]\n",
      " [29.729008 ]\n",
      " [29.232859 ]\n",
      " [13.371837 ]\n",
      " [26.787233 ]\n",
      " [ 5.629348 ]\n",
      " [ 8.234832 ]\n",
      " [28.7454   ]\n",
      " [19.14097  ]\n",
      " [29.72192  ]\n",
      " [ 5.8861084]\n",
      " [19.517204 ]\n",
      " [28.48834  ]\n",
      " [11.712585 ]\n",
      " [22.062458 ]\n",
      " [29.881935 ]\n",
      " [ 7.639571 ]\n",
      " [13.614893 ]\n",
      " [29.871965 ]\n",
      " [29.678629 ]\n",
      " [27.770483 ]\n",
      " [19.554193 ]\n",
      " [28.516027 ]\n",
      " [26.393816 ]\n",
      " [15.942386 ]\n",
      " [28.994902 ]\n",
      " [ 5.696005 ]\n",
      " [11.118883 ]\n",
      " [29.507603 ]\n",
      " [ 9.172627 ]\n",
      " [29.692364 ]\n",
      " [ 7.77643  ]\n",
      " [19.065828 ]\n",
      " [29.273045 ]\n",
      " [29.466362 ]\n",
      " [15.9607115]\n",
      " [24.090416 ]\n",
      " [21.441504 ]\n",
      " [29.551441 ]\n",
      " [ 7.67949  ]\n",
      " [16.23645  ]\n",
      " [ 9.519047 ]\n",
      " [20.497158 ]\n",
      " [28.723917 ]\n",
      " [18.786745 ]\n",
      " [28.953142 ]\n",
      " [29.863224 ]\n",
      " [10.3874035]\n",
      " [25.506805 ]\n",
      " [29.616846 ]\n",
      " [16.037123 ]\n",
      " [ 7.245365 ]\n",
      " [17.961672 ]\n",
      " [ 5.726015 ]\n",
      " [ 5.908721 ]\n",
      " [ 5.6299877]\n",
      " [20.367113 ]\n",
      " [ 5.6465197]\n",
      " [ 5.6523266]\n",
      " [ 8.543564 ]\n",
      " [13.820046 ]\n",
      " [11.19761  ]\n",
      " [25.292    ]\n",
      " [ 7.185961 ]\n",
      " [25.44374  ]\n",
      " [29.880556 ]\n",
      " [ 6.378771 ]\n",
      " [ 5.643115 ]\n",
      " [25.033031 ]\n",
      " [ 5.641548 ]\n",
      " [ 5.6289663]\n",
      " [ 5.6703844]\n",
      " [12.280367 ]\n",
      " [19.413801 ]\n",
      " [ 8.286422 ]\n",
      " [26.072844 ]\n",
      " [ 8.972028 ]\n",
      " [ 7.7295885]\n",
      " [27.748878 ]\n",
      " [25.841246 ]\n",
      " [ 5.646843 ]\n",
      " [29.880573 ]\n",
      " [ 5.724003 ]\n",
      " [16.589714 ]\n",
      " [29.878824 ]\n",
      " [15.27816  ]\n",
      " [12.732587 ]\n",
      " [ 6.0416307]\n",
      " [13.1940365]\n",
      " [23.721039 ]\n",
      " [29.816284 ]\n",
      " [29.881939 ]\n",
      " [18.297726 ]\n",
      " [29.27285  ]\n",
      " [29.654718 ]\n",
      " [27.580542 ]\n",
      " [23.331167 ]\n",
      " [29.645256 ]\n",
      " [29.882067 ]\n",
      " [13.243777 ]\n",
      " [29.82092  ]\n",
      " [27.977875 ]\n",
      " [12.463883 ]\n",
      " [21.551926 ]\n",
      " [28.173393 ]\n",
      " [ 5.6307116]\n",
      " [ 5.6304464]\n",
      " [25.849937 ]\n",
      " [29.865255 ]\n",
      " [29.171196 ]\n",
      " [29.375435 ]\n",
      " [ 9.7259655]\n",
      " [26.618862 ]\n",
      " [ 5.6726046]\n",
      " [29.530304 ]\n",
      " [ 5.8944674]\n",
      " [13.104218 ]\n",
      " [ 6.8462543]\n",
      " [18.899282 ]\n",
      " [10.435956 ]\n",
      " [29.881634 ]\n",
      " [29.87482  ]\n",
      " [22.891031 ]\n",
      " [ 6.281743 ]\n",
      " [16.712837 ]\n",
      " [11.581075 ]\n",
      " [28.551008 ]\n",
      " [20.84634  ]\n",
      " [ 5.628933 ]\n",
      " [14.567621 ]\n",
      " [ 8.699383 ]\n",
      " [10.2034235]\n",
      " [17.749292 ]\n",
      " [27.48843  ]\n",
      " [29.009481 ]\n",
      " [29.881912 ]\n",
      " [21.138718 ]\n",
      " [12.500381 ]\n",
      " [12.433157 ]\n",
      " [29.83415  ]\n",
      " [28.155106 ]\n",
      " [29.881985 ]\n",
      " [ 6.852275 ]\n",
      " [29.881628 ]\n",
      " [19.356403 ]\n",
      " [29.66338  ]\n",
      " [23.71522  ]\n",
      " [ 9.4938965]\n",
      " [22.029581 ]\n",
      " [18.571999 ]\n",
      " [ 8.753831 ]\n",
      " [29.423683 ]\n",
      " [23.196537 ]\n",
      " [18.733498 ]\n",
      " [11.749976 ]\n",
      " [17.442657 ]\n",
      " [15.582629 ]\n",
      " [18.047182 ]\n",
      " [24.707968 ]\n",
      " [29.879942 ]\n",
      " [20.519682 ]\n",
      " [14.596223 ]\n",
      " [ 8.949758 ]\n",
      " [20.79395  ]\n",
      " [26.632658 ]\n",
      " [13.681614 ]\n",
      " [29.88205  ]\n",
      " [ 6.7866716]\n",
      " [29.880043 ]\n",
      " [ 5.630432 ]\n",
      " [10.537634 ]\n",
      " [29.251925 ]\n",
      " [11.270209 ]\n",
      " [15.364377 ]\n",
      " [24.019648 ]\n",
      " [ 9.806667 ]\n",
      " [ 6.6750803]\n",
      " [ 5.643017 ]\n",
      " [14.666549 ]\n",
      " [28.245464 ]\n",
      " [ 5.656204 ]\n",
      " [18.820219 ]\n",
      " [29.859936 ]\n",
      " [11.170658 ]\n",
      " [28.487213 ]\n",
      " [29.812092 ]\n",
      " [ 5.630225 ]\n",
      " [16.900696 ]\n",
      " [26.392275 ]\n",
      " [29.840235 ]\n",
      " [10.85459  ]\n",
      " [18.129675 ]\n",
      " [29.880508 ]\n",
      " [ 5.781575 ]\n",
      " [16.442984 ]\n",
      " [23.131329 ]\n",
      " [29.505913 ]\n",
      " [29.87994  ]\n",
      " [ 6.581339 ]\n",
      " [ 5.633498 ]\n",
      " [15.202231 ]\n",
      " [28.54919  ]\n",
      " [ 6.6034403]\n",
      " [23.912317 ]\n",
      " [27.444365 ]\n",
      " [ 6.456256 ]\n",
      " [11.9583235]\n",
      " [27.402216 ]\n",
      " [20.568815 ]\n",
      " [24.00501  ]\n",
      " [10.347173 ]\n",
      " [17.053402 ]\n",
      " [24.872551 ]\n",
      " [29.859652 ]\n",
      " [28.38391  ]\n",
      " [26.834085 ]\n",
      " [29.36995  ]\n",
      " [14.16253  ]\n",
      " [12.9418545]\n",
      " [29.88018  ]\n",
      " [29.248587 ]\n",
      " [23.576609 ]\n",
      " [26.387613 ]\n",
      " [25.217913 ]\n",
      " [ 8.000489 ]\n",
      " [ 6.523301 ]\n",
      " [ 5.66459  ]\n",
      " [ 7.8904943]\n",
      " [18.361052 ]\n",
      " [11.459754 ]\n",
      " [19.235    ]\n",
      " [11.973638 ]\n",
      " [ 7.7813663]\n",
      " [29.80588  ]\n",
      " [10.145212 ]\n",
      " [18.205135 ]\n",
      " [10.358508 ]\n",
      " [ 5.7755613]\n",
      " [29.39128  ]\n",
      " [25.266762 ]\n",
      " [10.190241 ]\n",
      " [29.87778  ]\n",
      " [20.934887 ]\n",
      " [15.680729 ]\n",
      " [25.06669  ]\n",
      " [29.140873 ]\n",
      " [29.881693 ]\n",
      " [13.790949 ]\n",
      " [ 8.362059 ]\n",
      " [19.10332  ]\n",
      " [28.201496 ]\n",
      " [20.091894 ]\n",
      " [ 7.1342564]\n",
      " [25.689722 ]\n",
      " [ 5.632698 ]\n",
      " [12.282613 ]\n",
      " [29.88132  ]\n",
      " [11.0302725]\n",
      " [ 6.4466295]\n",
      " [29.007584 ]\n",
      " [ 5.633916 ]\n",
      " [11.088805 ]\n",
      " [22.995687 ]\n",
      " [ 7.330885 ]\n",
      " [29.88191  ]\n",
      " [12.446078 ]\n",
      " [ 5.6344404]\n",
      " [ 5.85359  ]\n",
      " [13.058444 ]\n",
      " [20.21364  ]\n",
      " [12.242688 ]\n",
      " [25.614632 ]\n",
      " [28.631681 ]\n",
      " [29.86712  ]\n",
      " [29.860022 ]\n",
      " [12.176996 ]\n",
      " [29.860023 ]\n",
      " [ 5.7642393]\n",
      " [27.449568 ]\n",
      " [ 5.629133 ]\n",
      " [ 5.6342115]\n",
      " [21.742027 ]\n",
      " [20.990946 ]\n",
      " [26.577335 ]\n",
      " [29.567198 ]\n",
      " [ 5.6290903]\n",
      " [29.854288 ]\n",
      " [10.434854 ]\n",
      " [25.0121   ]\n",
      " [20.627457 ]\n",
      " [ 7.479127 ]\n",
      " [24.410604 ]\n",
      " [ 5.947854 ]\n",
      " [18.534122 ]\n",
      " [ 7.089265 ]\n",
      " [ 6.1301565]\n",
      " [25.685951 ]\n",
      " [28.420559 ]\n",
      " [19.038628 ]\n",
      " [ 5.7780066]\n",
      " [28.800016 ]\n",
      " [13.73882  ]\n",
      " [10.965669 ]\n",
      " [25.366049 ]\n",
      " [ 5.790312 ]\n",
      " [29.879347 ]\n",
      " [ 5.634384 ]\n",
      " [22.691788 ]\n",
      " [29.88207  ]\n",
      " [ 5.6289387]\n",
      " [18.559391 ]\n",
      " [ 6.043046 ]\n",
      " [ 6.0227613]\n",
      " [15.632057 ]\n",
      " [29.88198  ]\n",
      " [29.879597 ]\n",
      " [10.944396 ]\n",
      " [28.360846 ]\n",
      " [ 9.1951065]\n",
      " [29.881474 ]\n",
      " [24.95212  ]\n",
      " [24.696865 ]\n",
      " [ 5.6294374]\n",
      " [13.0567665]\n",
      " [24.237366 ]\n",
      " [12.52105  ]\n",
      " [24.424953 ]\n",
      " [24.840029 ]\n",
      " [29.881783 ]\n",
      " [15.255086 ]\n",
      " [22.884056 ]\n",
      " [26.4476   ]\n",
      " [22.77551  ]\n",
      " [ 5.6395197]\n",
      " [ 7.2526894]\n",
      " [22.948833 ]\n",
      " [23.953602 ]\n",
      " [21.979534 ]\n",
      " [16.986162 ]\n",
      " [10.157327 ]\n",
      " [ 9.417563 ]\n",
      " [29.834877 ]\n",
      " [11.221966 ]\n",
      " [29.878038 ]\n",
      " [29.601755 ]\n",
      " [23.55239  ]\n",
      " [29.845781 ]\n",
      " [20.852758 ]\n",
      " [19.188549 ]\n",
      " [ 5.633317 ]\n",
      " [13.155215 ]\n",
      " [27.31305  ]\n",
      " [26.483097 ]\n",
      " [ 7.1089306]\n",
      " [29.88204  ]\n",
      " [ 8.481882 ]\n",
      " [24.522102 ]\n",
      " [ 8.335965 ]\n",
      " [ 6.252784 ]\n",
      " [13.368471 ]\n",
      " [29.86653  ]\n",
      " [ 6.706568 ]\n",
      " [23.553057 ]\n",
      " [ 9.566171 ]\n",
      " [21.074293 ]\n",
      " [ 5.6289682]\n",
      " [ 9.627797 ]\n",
      " [ 5.6290827]\n",
      " [28.093096 ]\n",
      " [25.50029  ]\n",
      " [27.404388 ]\n",
      " [27.756306 ]\n",
      " [29.411188 ]\n",
      " [29.685577 ]\n",
      " [23.996716 ]\n",
      " [28.258072 ]\n",
      " [29.881744 ]\n",
      " [24.768204 ]\n",
      " [29.178146 ]\n",
      " [29.852888 ]\n",
      " [17.130909 ]\n",
      " [22.140898 ]\n",
      " [29.881681 ]\n",
      " [ 5.641596 ]\n",
      " [23.689642 ]\n",
      " [13.453681 ]\n",
      " [29.878862 ]\n",
      " [26.033222 ]\n",
      " [ 5.6835585]\n",
      " [ 9.181925 ]\n",
      " [26.833544 ]\n",
      " [ 5.631241 ]\n",
      " [ 5.6293964]\n",
      " [17.144531 ]\n",
      " [26.923819 ]\n",
      " [ 5.631343 ]\n",
      " [27.242527 ]\n",
      " [27.32176  ]\n",
      " [29.88169  ]\n",
      " [29.880108 ]\n",
      " [13.882396 ]\n",
      " [13.467018 ]\n",
      " [25.061924 ]\n",
      " [ 7.4704504]\n",
      " [17.204458 ]\n",
      " [15.37413  ]\n",
      " [ 9.713329 ]\n",
      " [29.879921 ]\n",
      " [27.724802 ]\n",
      " [17.883228 ]\n",
      " [ 6.1552067]\n",
      " [ 5.6292114]\n",
      " [ 5.628993 ]\n",
      " [12.430123 ]\n",
      " [20.649866 ]\n",
      " [18.183197 ]\n",
      " [18.578194 ]\n",
      " [15.601325 ]\n",
      " [29.79905  ]\n",
      " [14.544298 ]\n",
      " [14.171018 ]\n",
      " [13.425737 ]\n",
      " [ 8.200047 ]\n",
      " [ 5.906165 ]\n",
      " [ 5.6430864]\n",
      " [28.971066 ]\n",
      " [29.88206  ]\n",
      " [ 7.501069 ]\n",
      " [29.847006 ]\n",
      " [ 7.641615 ]\n",
      " [ 6.651516 ]\n",
      " [27.024883 ]\n",
      " [ 5.725416 ]\n",
      " [29.25674  ]\n",
      " [29.85149  ]\n",
      " [27.909513 ]\n",
      " [29.842749 ]\n",
      " [ 7.868471 ]\n",
      " [24.677    ]\n",
      " [ 5.6290855]\n",
      " [ 9.764136 ]\n",
      " [11.308355 ]\n",
      " [18.406528 ]\n",
      " [15.874062 ]\n",
      " [ 5.8303204]\n",
      " [ 5.791157 ]\n",
      " [29.881643 ]\n",
      " [15.603727 ]\n",
      " [29.036615 ]\n",
      " [22.464329 ]\n",
      " [16.69013  ]\n",
      " [10.295026 ]\n",
      " [12.912877 ]\n",
      " [ 7.6791973]\n",
      " [ 6.378463 ]\n",
      " [15.763421 ]\n",
      " [17.994698 ]\n",
      " [27.787537 ]\n",
      " [29.782045 ]\n",
      " [ 5.8802757]\n",
      " [ 5.654421 ]\n",
      " [16.148628 ]\n",
      " [21.446823 ]\n",
      " [21.33432  ]\n",
      " [18.04053  ]\n",
      " [14.883041 ]\n",
      " [12.981776 ]\n",
      " [ 5.6289406]\n",
      " [ 8.973566 ]\n",
      " [28.713072 ]\n",
      " [20.070627 ]\n",
      " [16.0827   ]\n",
      " [26.719372 ]\n",
      " [ 5.64038  ]\n",
      " [13.316872 ]\n",
      " [ 5.836668 ]\n",
      " [ 5.6512623]\n",
      " [ 5.628954 ]\n",
      " [23.030682 ]\n",
      " [19.004377 ]\n",
      " [29.882067 ]\n",
      " [ 5.6297293]\n",
      " [ 5.6289387]\n",
      " [ 7.046462 ]\n",
      " [20.58666  ]\n",
      " [ 5.660223 ]\n",
      " [19.066978 ]\n",
      " [13.503968 ]\n",
      " [ 9.583331 ]\n",
      " [29.344042 ]\n",
      " [29.873293 ]\n",
      " [ 6.3431826]\n",
      " [17.275574 ]\n",
      " [13.552813 ]\n",
      " [22.219082 ]\n",
      " [29.877392 ]\n",
      " [ 7.7218494]\n",
      " [29.881044 ]\n",
      " [17.279884 ]\n",
      " [10.463237 ]\n",
      " [25.964249 ]\n",
      " [12.109214 ]\n",
      " [29.233492 ]\n",
      " [29.636824 ]\n",
      " [29.873682 ]\n",
      " [ 5.6290216]\n",
      " [29.717493 ]\n",
      " [ 7.158759 ]\n",
      " [29.868387 ]\n",
      " [18.213917 ]\n",
      " [24.706276 ]\n",
      " [12.113904 ]\n",
      " [29.881992 ]\n",
      " [19.714571 ]\n",
      " [10.685924 ]\n",
      " [13.0305605]\n",
      " [ 5.6289406]\n",
      " [ 5.736472 ]\n",
      " [ 6.8874006]\n",
      " [12.994626 ]\n",
      " [28.660639 ]\n",
      " [21.60059  ]\n",
      " [10.539532 ]\n",
      " [29.631966 ]\n",
      " [24.832193 ]\n",
      " [27.340916 ]\n",
      " [22.885714 ]\n",
      " [24.726448 ]\n",
      " [11.851806 ]\n",
      " [24.873474 ]\n",
      " [27.167698 ]\n",
      " [25.20653  ]\n",
      " [28.67231  ]\n",
      " [ 5.641321 ]\n",
      " [24.60804  ]\n",
      " [15.19042  ]\n",
      " [28.23569  ]\n",
      " [26.121656 ]\n",
      " [18.072407 ]\n",
      " [ 5.660699 ]\n",
      " [29.482712 ]\n",
      " [18.93076  ]\n",
      " [ 8.179409 ]\n",
      " [27.712894 ]\n",
      " [24.981346 ]\n",
      " [ 7.046878 ]\n",
      " [ 9.541418 ]\n",
      " [29.483625 ]\n",
      " [22.369848 ]\n",
      " [20.166037 ]\n",
      " [29.598776 ]\n",
      " [21.615078 ]\n",
      " [ 5.6328115]\n",
      " [29.863504 ]\n",
      " [25.54847  ]\n",
      " [25.514864 ]\n",
      " [29.88197  ]\n",
      " [ 6.303068 ]\n",
      " [ 7.62875  ]\n",
      " [17.12769  ]\n",
      " [14.621135 ]\n",
      " [24.637512 ]\n",
      " [ 7.505554 ]\n",
      " [16.10704  ]\n",
      " [15.212103 ]\n",
      " [29.881266 ]\n",
      " [ 5.630575 ]\n",
      " [20.836847 ]\n",
      " [27.80745  ]\n",
      " [ 5.6477222]\n",
      " [ 9.267909 ]\n",
      " [15.909126 ]\n",
      " [27.195889 ]\n",
      " [ 5.656067 ]\n",
      " [12.519838 ]\n",
      " [26.054676 ]\n",
      " [10.787338 ]\n",
      " [29.865679 ]\n",
      " [26.143492 ]\n",
      " [13.274652 ]\n",
      " [17.422197 ]\n",
      " [ 8.009528 ]\n",
      " [26.634827 ]\n",
      " [ 5.6485367]\n",
      " [27.3725   ]\n",
      " [16.672604 ]\n",
      " [29.656654 ]\n",
      " [16.991724 ]\n",
      " [14.912003 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_predict = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test.numpy(), y_predict)\n",
    "y_predict = scaler_y.inverse_transform(y_predict)\n",
    "print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
